{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading feature info...\n",
      "Finding column indices for feature types...\n",
      "Reading csv files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "Preprocessing...\n",
      "Converting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:42: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:43: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:45: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use Series.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing NaNs...\n",
      "Stripping nominal columns and setting them lower case...\n",
      "Changing targets 'backdoors' to 'backdoor'...\n",
      "Slicing dataset...\n",
      "Vectorizing nominal data...\n",
      "Concatenating X...\n",
      "Removing NaNs if any...\n",
      "Normalizing X...\n",
      "Data dimensions are (2539739, 294)\n",
      "Creating target Y matrix...\n",
      "Vectorizing Y labels...\n",
      "Saving normalized X and labeled Y to HDF5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas \n",
    "\n",
    "from sklearn.preprocessing import normalize # , LabelEncoder\n",
    "\n",
    "# Read the info about features\n",
    "print('Reading feature info...')\n",
    "data_info = pandas.read_csv(\"NUSW-NB15_features.csv\", encoding = \"ISO-8859-1\", header=None).values\n",
    "features = data_info[1:-2,:]\n",
    "feature_names = features[:, 1]  # Names of the features in a list\n",
    "feature_types = np.array([item.lower() for item in features[:, 2]])  # The types of the corresponding features in 'features_names'\n",
    "                         \n",
    "# index arrays for different types of features\n",
    "print('Finding column indices for feature types...')\n",
    "nominal_cols = np.where(feature_types == \"nominal\")[0]\n",
    "integer_cols = np.where(feature_types == \"integer\")[0]\n",
    "binary_cols = np.where(feature_types == \"binary\")[0]\n",
    "float_cols = np.where(feature_types == \"float\")[0]\n",
    "\n",
    "# arrays for names of the different types of features\n",
    "nominal_names = feature_names[nominal_cols]\n",
    "integer_names = feature_names[integer_cols]\n",
    "binary_names = feature_names[binary_cols]\n",
    "float_names = feature_names[float_cols]\n",
    "\n",
    "print('Reading csv files...')\n",
    "dataframe1 = pandas.read_csv(\"UNSW-NB15_1.csv\", header=None)\n",
    "dataframe2 = pandas.read_csv(\"UNSW-NB15_2.csv\", header=None)\n",
    "dataframe3 = pandas.read_csv(\"UNSW-NB15_3.csv\", header=None)\n",
    "dataframe4 = pandas.read_csv(\"UNSW-NB15_4.csv\", header=None)\n",
    "\n",
    "print('Concatenating...')\n",
    "dataframe = pandas.concat([dataframe1, dataframe2, dataframe3, dataframe4])\n",
    "\n",
    "del dataframe1\n",
    "del dataframe2\n",
    "del dataframe3\n",
    "del dataframe4\n",
    "\n",
    "print('Preprocessing...')\n",
    "print('Converting data...')\n",
    "dataframe[integer_cols] = dataframe[integer_cols].convert_objects(convert_numeric=True)\n",
    "dataframe[binary_cols] = dataframe[binary_cols].convert_objects(convert_numeric=True)\n",
    "dataframe[float_cols] = dataframe[float_cols].convert_objects(convert_numeric=True)\n",
    "dataframe[48] = dataframe[48].convert_objects(convert_numeric=True)\n",
    "#dataframe[nominal_cols] = dataframe[nominal_cols].astype(str)\n",
    "\n",
    "print('Replacing NaNs...')\n",
    "dataframe.loc[:,47] = dataframe.loc[:,47].replace(np.nan,'normal', regex=True).apply(lambda x: x.strip().lower())\n",
    "dataframe.loc[:,binary_cols] = dataframe.loc[:,binary_cols].replace(np.nan, 0, regex=True)\n",
    "dataframe.loc[:,37:39] = dataframe.loc[:,37:39].replace(np.nan, 0, regex=True)\n",
    "# dataframe.loc[:,float_cols] = dataframe.loc[:,float_cols].replace(np.nan, 0, regex=True)\n",
    "\n",
    "print('Stripping nominal columns and setting them lower case...')\n",
    "dataframe.loc[:,nominal_cols] = dataframe.loc[:,nominal_cols].applymap(lambda x: x.strip().lower())\n",
    "\n",
    "print('Changing targets \\'backdoors\\' to \\'backdoor\\'...')\n",
    "dataframe.loc[:,47] = dataframe.loc[:,47].replace('backdoors','backdoor', regex=True).apply(lambda x: x.strip().lower())\n",
    "\n",
    "dataset = dataframe.values\n",
    "\n",
    "del dataframe\n",
    "\n",
    "# Subsets of the dataset which have data that is only of the corresponding data type (nominal, integer etc)\n",
    "# Columns don't include the target classes (the two last columns of the dataset)\n",
    "print('Slicing dataset...')\n",
    "nominal_x = dataset[:, nominal_cols][:,:]\n",
    "integer_x = dataset[:, integer_cols][:,:].astype(np.float32)    \n",
    "binary_x = dataset[:, binary_cols][:,:].astype(np.float32)\n",
    "float_x = dataset[:, float_cols][:,:].astype(np.float32)\n",
    "# aon_x = dataset[:, 48][np.newaxis,:].astype(np.float32).transpose()  # Attack or not (binary)\n",
    "\n",
    "# Make nominal (textual) data binary vectors\n",
    "print('Vectorizing nominal data...')\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=False)\n",
    "# D = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\n",
    "D = map(lambda dataline: dict(zip(nominal_names, dataline)), nominal_x)\n",
    "labeled_nominal_x = v.fit_transform(D).astype(np.float32)\n",
    "del nominal_x\n",
    "\n",
    "print('Concatenating X...')\n",
    "X = np.concatenate((integer_x, labeled_nominal_x, float_x, binary_x), axis=1)\n",
    "\n",
    "del integer_x\n",
    "del labeled_nominal_x\n",
    "del float_x\n",
    "del binary_x\n",
    "\n",
    "# Find rows that have NaNs\n",
    "print('Removing NaNs if any...')\n",
    "nan_indices = []\n",
    "for feature_i in range(X.shape[1]):\n",
    "    nan_indices.extend(list(np.where(np.isnan(X[:, feature_i]))[0]))\n",
    "nan_indices = np.unique(nan_indices)\n",
    "\n",
    "# Remove rows that have NaNs\n",
    "X_no_nans = np.delete(X, nan_indices, axis=0)\n",
    "\n",
    "del X\n",
    "\n",
    "print('Normalizing X...')\n",
    "normalized_X = normalize(X_no_nans, copy=False)\n",
    "\n",
    "del X_no_nans\n",
    "\n",
    "\n",
    "data_dim = normalized_X.shape\n",
    "print('Data dimensions are', data_dim)\n",
    "\n",
    "print('Creating target Y matrix...')\n",
    "Y = np.delete(dataset[:, -2], nan_indices)\n",
    "Y_A = np.delete(dataset[:, -1], nan_indices).astype(np.int16) # Is attack or not\n",
    "\n",
    "del dataset\n",
    "\n",
    "'''\n",
    "# Remove same rows as in X to have correct y's\n",
    "Y_no_nans = np.delete(Y, nan_indices, axis=0)\n",
    "'''\n",
    "print('Vectorizing Y labels...')\n",
    "D = [{'attack_cat': y} for y in Y]\n",
    "labeled_Y = v.fit_transform(D)\n",
    "\n",
    "del D\n",
    "\n",
    "print('Saving normalized X and labeled Y to HDF5')\n",
    "import h5py\n",
    "h5f = h5py.File('data.h5', 'w')\n",
    "h5f.create_dataset('normalized_X', data=normalized_X)\n",
    "h5f.create_dataset('labeled_Y', data=labeled_Y)\n",
    "dt = h5py.special_dtype(vlen=str)\n",
    "h5f.create_dataset('Y', data=Y, dtype=dt)\n",
    "h5f.create_dataset('Y_A', data=Y_A)\n",
    "h5f.close()\n",
    "\n",
    "del Y\n",
    "del normalized_X\n",
    "del labeled_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
